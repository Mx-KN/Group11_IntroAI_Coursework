{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96ffb97",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# BTC Historical Data Analysis and Classification\n",
    "\n",
    "Bitcoin (BTC), known for its high volatility, presents a unique opportunity for predictive modeling in financial markets. The objective of this notebook is to explore whether machine learning techniques like **Logistic Regression** and **Random Forest Classification** can accurately predict the direction of BTC's price movement based on historical trading data.\n",
    "\n",
    "The classification task is framed as a binary prediction problem: will the BTC price increase or decrease after a specified number of days (`lookahead_days`)? Success in this task could provide valuable insights for designing trading strategies. However, the inherent complexity and noise in financial data require careful preprocessing, feature engineering, and model selection to achieve meaningful results.\n",
    "\n",
    "We structure the analysis by first engineering features tailored to capture BTC price patterns, followed by training and evaluating both models. The comparison highlights how logistic regression, a linear model, struggles with non-linear patterns, and why Random Forest, a more flexible algorithm, might offer better performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "The quality of the features used can significantly influence the performance of a predictive model. For this task, we opted to create indicators commonly used in financial analysis, balancing simplicity with effectiveness:\n",
    "\n",
    "1. **Moving Averages (MA):**\n",
    "   These smooth out short-term fluctuations in price, helping to capture overall trends. We chose 7, 14, and 30-day windows to provide varying perspectives on price movement over different time frames. This decision ensures both short-term dynamics and broader trends are accounted for.\n",
    "\n",
    "2. **Relative Strength Index (RSI):**\n",
    "   RSI measures price momentum, helping identify overbought or oversold conditions. This feature was included to capture scenarios where price reversals might occur. Momentum indicators like RSI often add depth to trend-following features like moving averages.\n",
    "\n",
    "3. **Bollinger Bands:**\n",
    "   Volatility plays a critical role in cryptocurrency markets. By incorporating Bollinger Bands, which measure price deviations from a moving average, the model can account for periods of high volatility where prices deviate significantly.\n",
    "\n",
    "4. **Volume-Based Indicators:**\n",
    "   Volume can often signal upcoming price changes. A 7-day average of trading volume was chosen to highlight shifts in market activity, complementing price-based features.\n",
    "\n",
    "These features were selected to provide a comprehensive yet interpretable view of the market. While they are straightforward, they align well with the domain knowledge of financial markets, making them robust starting points for model training.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Details\n",
    "\n",
    "The dataset includes key trading metrics such as opening price, closing price, highest and lowest price, and traded volume. We define the target variable as binary: \n",
    "\n",
    "- `1` if the BTC price increases after the specified `lookahead_days`.\n",
    "- `0` if the BTC price decreases.\n",
    "\n",
    "This simple formulation allows us to focus on evaluating the models' capabilities in capturing price direction rather than precise numerical predictions.\n",
    "\n",
    "While logistic regression serves as a baseline due to its simplicity and interpretability, the dataset's complexity and the likely presence of non-linear patterns in BTC price movement motivate the inclusion of Random Forest. This approach reflects a progression from understanding fundamental relationships to leveraging a model capable of capturing more intricate interactions.\n",
    "\n",
    "By iteratively building upon these features and evaluating model performance, we aim to strike a balance between interpretability and predictive power. This process ensures that each decision is deliberate and grounded in the requirements of the task. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e0248",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Import necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44453737",
   "metadata": {},
   "source": [
    "The `load_and_preprocess` function focuses on preparing the raw BTC dataset for analysis and model training by integrating the feature engineering described earlier. It begins by importing the data, standardizing column names, converting dates to a usable format, and sorting the dataset chronologically to maintain the integrity of time-series data.\n",
    "\n",
    "The primary objective of this function is to apply the predefined feature engineering pipeline—such as calculating moving averages, RSI, Bollinger Bands, and volume-based metrics—while ensuring compatibility for model training. It also defines the binary target variable (`1` for a price increase and `0` for a decrease) using a forward-looking approach based on `lookahead_days`. \n",
    "\n",
    "To finalize the preparation, any rows containing null values—introduced during rolling window calculations—are removed, ensuring a clean and complete dataset. This function operationalizes the feature engineering strategy and outputs a dataset ready for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d56013",
   "metadata": {
    "explanation": "\n### Explanation: Data Loading and Preprocessing\n- The `load_and_preprocess` function is responsible for reading the BTC historical dataset and engineering features that can improve model performance.\n- Features added:\n  1. **Moving Averages (7-day, 14-day, 30-day):** Captures short-term and long-term trends in closing prices.\n  2. **RSI (Relative Strength Index):** Indicates momentum and whether the market is overbought or oversold.\n  3. **Bollinger Bands:** Measures volatility with upper and lower bounds around a moving average.\n  4. **Volume Indicators:** The 7-day average of trading volume.\n- The function also creates a target variable (`1` if the price goes up, `0` if it goes down) based on a look-ahead period (`lookahead_days`).\n\nThis preprocessing prepares the dataset for training models.\n"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/bedikudor/Documents/UNI_Third_Year/Term1/AI/Group11_IntroAI_Coursework/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Data\n",
    "def load_and_preprocess(csv_path, lookahead_days):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date')\n",
    "\n",
    "    # Feature Engineering\n",
    "    df['ma_7day'] = df['close'].rolling(7).mean()\n",
    "    df['ma_14day'] = df['close'].rolling(14).mean()\n",
    "    df['ma_30day'] = df['close'].rolling(30).mean()\n",
    "\n",
    "    # RSI Calculation\n",
    "    df['price_change'] = df['close'].diff()\n",
    "    df['gain'] = df['price_change'].clip(lower=0)\n",
    "    df['loss'] = -1 * df['price_change'].clip(upper=0)\n",
    "    avg_gain = df['gain'].rolling(14).mean()\n",
    "    avg_loss = df['loss'].rolling(14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['rsi'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # Bollinger Bands\n",
    "    df['bb_middle'] = df['close'].rolling(20).mean()\n",
    "    df['bb_std'] = df['close'].rolling(20).std()\n",
    "    df['bb_upper'] = df['bb_middle'] + (2 * df['bb_std'])\n",
    "    df['bb_lower'] = df['bb_middle'] - (2 * df['bb_std'])\n",
    "\n",
    "    # Volume-Based Indicators\n",
    "    df['volume_ma_7day'] = df['volume'].rolling(7).mean()\n",
    "\n",
    "    # Target Variable\n",
    "    df['future_close'] = df['close'].shift(-lookahead_days)\n",
    "    df['target'] = (df['future_close'] > df['close']).astype(int)\n",
    "\n",
    "    # Drop rows with null values\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Dataset Path\n",
    "csv_path = \"../data/raw/btc_usd.csv\"\n",
    "df = load_and_preprocess(csv_path, lookahead_days=7)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5f1b1",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "The `feature_columns` list specifies the input features that will be used for model training. These include raw trading data (`open`, `high`, `low`, `volume`) as well as engineered features like moving averages, RSI, Bollinger Bands, and volume-based indicators. These features were chosen to capture a mix of trend, momentum, and volatility signals, providing a comprehensive view of BTC price dynamics. The variable `X` represents the feature set, while `y` holds the binary target variable (`1` for price increase, `0` for decrease).\n",
    "\n",
    "### Train-Test Split\n",
    "The data is split into two subsets:\n",
    "- **Training Set (`X_train`, `y_train`)**: Used for training the model, comprising 70% of the data.\n",
    "- **Testing Set (`X_test`, `y_test`)**: Used to evaluate model performance on unseen data, comprising the remaining 30%.\n",
    "\n",
    "The `random_state` parameter ensures that the split is reproducible, maintaining consistent results across runs. Splitting the data helps evaluate the model's ability to generalize rather than overfit to the training data.\n",
    "\n",
    "### Feature Scaling\n",
    "A `StandardScaler` is applied to standardize the feature values. This process centers each feature around a mean of 0 and scales it to have a standard deviation of 1:\n",
    "- **Training Data (`X_train_scaled`)**: The scaler computes the mean and standard deviation from the training data and scales the features accordingly.\n",
    "- **Testing Data (`X_test_scaled`)**: The same scaling parameters are applied to the testing data, ensuring consistency.\n",
    "\n",
    "Feature scaling is crucial for algorithms like Logistic Regression, as it prevents features with larger ranges (e.g., volume) from dominating the learning process, ensuring all features contribute equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002844ec",
   "metadata": {
    "explanation": "\n### Explanation: Train-Test Split and Feature Scaling\n- **Train-Test Split:** Splits the data into training (70%) and testing (30%) sets.\n- **Feature Scaling:** Standardizes features to have a mean of 0 and a standard deviation of 1, which is essential for models like logistic regression to perform optimally.\n"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define Features and Target\n",
    "feature_columns = [\n",
    "    'open', 'high', 'low', 'volume',\n",
    "    'ma_7day', 'ma_14day', 'ma_30day', 'rsi',\n",
    "    'bb_upper', 'bb_lower', 'bb_middle', 'volume_ma_7day'\n",
    "]\n",
    "X = df[feature_columns]\n",
    "y = df['target']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24e18d7",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Logistic regression is chosen as a baseline model for this classification task due to its simplicity and interpretability. It assumes a linear relationship between the features and the log-odds of the target variable, making it a good starting point to understand how the features influence the outcome. The model is instantiated with a fixed random seed (`random_state=42`) for consistent results and a maximum iteration limit (`max_iter=500`) to ensure convergence during optimization.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Predictions\n",
    "\n",
    "Once trained, the logistic regression model is used to make predictions:\n",
    "- **Training Set Predictions**: The model predicts outcomes for the training set (`logistic_y_train_pred`) to assess how well it has captured patterns in the data it was trained on.\n",
    "- **Testing Set Predictions**: Predictions on the testing set (`logistic_y_test_pred`) are used to evaluate how well the model generalizes to unseen data.\n",
    "\n",
    "This dual evaluation provides a clearer picture of both overfitting and generalization performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Metrics Calculation\n",
    "\n",
    "To evaluate the logistic regression model, a range of metrics is computed:\n",
    "- **Training Accuracy**: Measures how well the model fits the training data. High accuracy here could indicate a strong fit, but overly high accuracy relative to testing accuracy might signal overfitting.\n",
    "- **Testing Accuracy**: Assesses the model's ability to generalize to unseen data, a critical factor in financial applications like BTC price prediction.\n",
    "- **Precision**: Indicates the quality of positive predictions. In financial tasks, precision can be important when false positives carry a high cost (e.g., predicting price increases that do not occur).\n",
    "- **Recall**: Reflects the model's ability to identify actual positive cases. In scenarios where missing opportunities (e.g., failing to predict a price increase) is costly, recall becomes vital.\n",
    "- **F1 Score**: Provides a balanced view of precision and recall, especially useful when there’s an imbalance between classes.\n",
    "- **Confusion Matrix**: Summarizes the prediction results into true positives, true negatives, false positives, and false negatives. This helps in understanding the types of errors the model is making.\n",
    "\n",
    "---\n",
    "\n",
    "### Thoughts on Logistic Regression\n",
    "\n",
    "Logistic regression is a strong baseline model, but it may struggle in capturing non-linear relationships and complex interactions between features, which are often present in financial datasets like BTC price movements. The results from this model will provide a benchmark to compare against more complex models, such as Random Forest, which can better handle non-linearities and feature interactions. This decision-making process ensures that the progression from simple to complex models is logical and data-driven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8a601",
   "metadata": {
    "explanation": "\n### Explanation: Logistic Regression Training and Predictions\n- A logistic regression model is trained on the scaled training dataset.\n- Predictions are made on both the training and testing datasets.\n- The model's performance is evaluated using:\n  - **Accuracy:** Proportion of correct predictions.\n  - **Precision:** Proportion of true positive predictions among all positive predictions.\n  - **Recall:** Proportion of true positive predictions among all actual positives.\n  - **F1 Score:** Harmonic mean of precision and recall.\n  - **Confusion Matrix:** A table summarizing prediction results.\n"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=500)\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Logistic Regression Predictions\n",
    "logistic_y_train_pred = logistic_model.predict(X_train_scaled)\n",
    "logistic_y_test_pred = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# Logistic Regression Metrics\n",
    "logistic_metrics = {\n",
    "    'train_accuracy': accuracy_score(y_train, logistic_y_train_pred),\n",
    "    'test_accuracy': accuracy_score(y_test, logistic_y_test_pred),\n",
    "    'precision': precision_score(y_test, logistic_y_test_pred),\n",
    "    'recall': recall_score(y_test, logistic_y_test_pred),\n",
    "    'f1_score': f1_score(y_test, logistic_y_test_pred),\n",
    "    'confusion_matrix': confusion_matrix(y_test, logistic_y_test_pred)\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7a7df",
   "metadata": {},
   "source": [
    "### Report on Logistic Regression Results\n",
    "\n",
    "The logistic regression model yielded the following metrics:\n",
    "\n",
    "- **Training Accuracy**: 56.15%\n",
    "- **Testing Accuracy**: 55.46%\n",
    "- **Precision**: 56.45%\n",
    "- **Recall**: 87.20%\n",
    "- **F1 Score**: 68.54%\n",
    "\n",
    "The **confusion matrix** shows significant imbalance in performance:\n",
    "```\n",
    "Confusion Matrix:\n",
    " [[ 77 415]\n",
    " [ 79 538]]\n",
    "```\n",
    "- **Class 0 (Price Decrease)**: The model performed poorly, with very few true negatives (77) and a large number of false positives (415).\n",
    "- **Class 1 (Price Increase)**: The model achieved high recall (538 true positives), but at the cost of precision, as false positives are prevalent.\n",
    "\n",
    "---\n",
    "\n",
    "### Thoughts on Results\n",
    "\n",
    "1. **Model Performance**:\n",
    "   - The low overall accuracy (~55%) indicates that the model struggles to differentiate between price increases and decreases effectively.\n",
    "   - The disparity between precision and recall suggests the model heavily favors predicting the positive class (`1`, price increase), leading to high recall but low precision.\n",
    "\n",
    "2. **Feature Engineering and Data**:\n",
    "   - Logistic regression assumes a **linear relationship** between features and the log-odds of the target variable. However, financial markets like BTC prices often exhibit **non-linear dynamics**, which linear models struggle to capture.\n",
    "   - While the engineered features (moving averages, RSI, Bollinger Bands) are robust, they might not fully encapsulate the non-linear interactions in the data.\n",
    "\n",
    "3. **Class Imbalance**:\n",
    "   - Although the target classes are not explicitly imbalanced, the model's prediction bias suggests that it struggles with misclassifying negative cases (price decreases). This could stem from subtle patterns in the data that logistic regression cannot pick up.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf4d851",
   "metadata": {},
   "source": [
    "\n",
    "## Experiment: Increasing the Lookahead Timeframe\n",
    "\n",
    "In this section, we explore the impact of varying the `lookahead_days` parameter on the model's performance. By increasing the lookahead period, we aim to observe how the model handles changes in the prediction window and whether it affects the accuracy, precision, recall, and other metrics.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1dd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define different lookahead timeframes to test\n",
    "timeframes = [7, 14, 30, 60]  # Lookahead periods in days\n",
    "results = {}\n",
    "\n",
    "for days in timeframes:\n",
    "    print(f\"Running for lookahead_days = {days}\")\n",
    "    lookahead_days = days  # Update the lookahead period\n",
    "    model, metrics = process_and_train_binary_classification(csv_path, lookahead_days=lookahead_days)\n",
    "    results[days] = metrics\n",
    "    print(f\"Results for lookahead_days = {days}: {metrics}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7aed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summarize and analyze results for different lookahead periods\n",
    "for days, metrics in results.items():\n",
    "    print(f\"\n",
    "Lookahead Days: {days}\")\n",
    "    print(metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d1ecf5",
   "metadata": {},
   "source": [
    "\n",
    "To further investigate the effect of the prediction window (`lookahead_days`), we will test the model with two extended periods: two weeks (`lookahead_days = 14`), one month (`lookahead_days = 30`) and  two months (`lookahead_days = 60`).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ecb15",
   "metadata": {},
   "source": [
    "\n",
    "## Final Analysis: Limitations of Logistic Regression and Transition to Random Forest\n",
    "\n",
    "### Observations from Lookahead Experiments\n",
    "\n",
    "#### Results Summary:\n",
    "- **Two Weeks (`lookahead_days = 14`)**:\n",
    "  - Training Accuracy: 58.19%\n",
    "  - Testing Accuracy: 56.10%\n",
    "  - F1 Score: 68.40%\n",
    "\n",
    "- **One Month (`lookahead_days = 30`)**:\n",
    "  - Training Accuracy: 59.69%\n",
    "  - Testing Accuracy: 58.89%\n",
    "  - F1 Score: 71.13%\n",
    "\n",
    "- **Two Months (`lookahead_days = 60`)**:\n",
    "  - Training Accuracy: 61.40%\n",
    "  - Testing Accuracy: 62.03%\n",
    "  - F1 Score: 72.99%\n",
    "\n",
    "As the lookahead period increases, the model's performance improves marginally, especially in terms of accuracy and F1 score. This indicates that longer timeframes reduce short-term noise and allow the model to identify more stable patterns. However, the confusion matrix still highlights persistent challenges in predicting price decreases (`0`), with low precision and recall for this class.\n",
    "\n",
    "### Why Logistic Regression Struggles\n",
    "\n",
    "1. **Linear Assumptions**:\n",
    "   Logistic regression assumes a linear relationship between features and the target, which is often too simplistic for financial data. BTC prices exhibit non-linear dynamics, where trends, momentum, and volatility interact in complex ways that logistic regression cannot capture.\n",
    "\n",
    "2. **Feature Sensitivity**:\n",
    "   Features like RSI and moving averages are more aligned with upward trends, introducing bias toward predicting price increases (`1`). This bias skews the confusion matrix, with many false positives for class `0`.\n",
    "\n",
    "3. **Class Imbalance**:\n",
    "   The model optimizes for overall accuracy, often favoring the dominant class (`1`) at the expense of precision for the minority class (`0`). This trade-off is evident in the low precision and recall for `0` across all experiments.\n",
    "\n",
    "### Why Random Forest Can Help\n",
    "\n",
    "1. **Non-Linear Relationships**:\n",
    "   Random Forest does not assume linearity and can capture complex patterns in the data by building multiple decision trees that split the feature space based on non-linear thresholds.\n",
    "\n",
    "2. **Feature Interactions**:\n",
    "   Random Forest naturally incorporates feature interactions, such as the combined effect of RSI and Bollinger Bands, which may be critical for distinguishing between upward and downward price movements.\n",
    "\n",
    "3. **Robustness to Noise**:\n",
    "   By averaging predictions across trees, Random Forest reduces sensitivity to noise, making it better suited for volatile financial data.\n",
    "\n",
    "4. **Balanced Performance**:\n",
    "   With hyperparameter tuning, Random Forest can address class imbalances, improving precision and recall for the minority class.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To address the limitations of logistic regression, the next logical step is to implement Random Forest. By leveraging its ability to handle non-linear relationships and interactions, we aim to achieve better-balanced predictions and improved performance across both classes.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
